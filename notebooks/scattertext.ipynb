{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns; sns.set(context='talk')\n",
    "from matplotlib import pyplot as plt, style; style.use('fivethirtyeight')\n",
    "\n",
    "import scattertext as st\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>primary_position</th>\n",
       "      <th>report</th>\n",
       "      <th>label</th>\n",
       "      <th>pos</th>\n",
       "      <th>parse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>**Luke Heimlich</td>\n",
       "      <td>LHP</td>\n",
       "      <td>Heimlich is a Level 1 sex offender and wouldn'...</td>\n",
       "      <td>MiLB</td>\n",
       "      <td>SP</td>\n",
       "      <td>(heimlich, is, a, level, 1, sex, offender, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>**Noah Song</td>\n",
       "      <td>RHP</td>\n",
       "      <td>The way teams value Song depends on whether or...</td>\n",
       "      <td>MiLB</td>\n",
       "      <td>SP</td>\n",
       "      <td>(the, way, teams, value, song, depends, on, wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A.J. Cole</td>\n",
       "      <td>RHP</td>\n",
       "      <td>The Nationals have acquired Cole twice, first...</td>\n",
       "      <td>MLB</td>\n",
       "      <td>SP</td>\n",
       "      <td>(the, nationals, have, acquired, cole, twice, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A.J. Cole</td>\n",
       "      <td>RHP</td>\n",
       "      <td>Signed for an above-slot $2 million as a Natio...</td>\n",
       "      <td>MLB</td>\n",
       "      <td>SP</td>\n",
       "      <td>(signed, for, an, above, -, slot, $, 2, millio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A.J. Cole</td>\n",
       "      <td>RHP</td>\n",
       "      <td>It often takes time for those high-ceilinged,...</td>\n",
       "      <td>MLB</td>\n",
       "      <td>SP</td>\n",
       "      <td>(it, often, takes, time, for, those, high, -, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name primary_position  \\\n",
       "0  **Luke Heimlich              LHP   \n",
       "1      **Noah Song              RHP   \n",
       "2        A.J. Cole              RHP   \n",
       "3        A.J. Cole              RHP   \n",
       "4        A.J. Cole              RHP   \n",
       "\n",
       "                                              report label pos  \\\n",
       "0  Heimlich is a Level 1 sex offender and wouldn'...  MiLB  SP   \n",
       "1  The way teams value Song depends on whether or...  MiLB  SP   \n",
       "2   The Nationals have acquired Cole twice, first...   MLB  SP   \n",
       "3  Signed for an above-slot $2 million as a Natio...   MLB  SP   \n",
       "4   It often takes time for those high-ceilinged,...   MLB  SP   \n",
       "\n",
       "                                               parse  \n",
       "0  (heimlich, is, a, level, 1, sex, offender, and...  \n",
       "1  (the, way, teams, value, song, depends, on, wh...  \n",
       "2  (the, nationals, have, acquired, cole, twice, ...  \n",
       "3  (signed, for, an, above, -, slot, $, 2, millio...  \n",
       "4  (it, often, takes, time, for, those, high, -, ...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7778, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>primary_position</th>\n",
       "      <th>report</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>pos</th>\n",
       "      <th>parse</th>\n",
       "      <th>parse_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4672</th>\n",
       "      <td>Kyle Tucker</td>\n",
       "      <td>OF</td>\n",
       "      <td>Houston had two of the first five picks in the...</td>\n",
       "      <td>MLB</td>\n",
       "      <td>PERSON had two of the first five picks in the ...</td>\n",
       "      <td>BAT</td>\n",
       "      <td>(houston, had, two, of, the, first, five, pick...</td>\n",
       "      <td>(person, had, two, of, the, first, five, picks...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name primary_position  \\\n",
       "4672  Kyle Tucker               OF   \n",
       "\n",
       "                                                 report label  \\\n",
       "4672  Houston had two of the first five picks in the...   MLB   \n",
       "\n",
       "                                                   text  pos  \\\n",
       "4672  PERSON had two of the first five picks in the ...  BAT   \n",
       "\n",
       "                                                  parse  \\\n",
       "4672  (houston, had, two, of, the, first, five, pick...   \n",
       "\n",
       "                                        parse_processed  \n",
       "4672  (person, had, two, of, the, first, five, picks...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fix_pos(x):\n",
    "    if x in ['LF', 'CF', 'RF']:\n",
    "        return 'OF'\n",
    "    elif x == 'INF':\n",
    "        return 'UTIL'\n",
    "    elif x == 'DH':\n",
    "        return '1B'\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "df = pd.read_csv('https://jacobdanovitch.blob.core.windows.net/datasets/twtc.csv', # 'https://github.com/jacobdanovitch/jdnlp/blob/master/datasets/twtc/twtc.csv?raw=true',\n",
    "                usecols = ['name', 'primary_position', 'report', 'label', 'text'])\n",
    "df = df[df.label != -1].reset_index(drop=True)\n",
    "\n",
    "\n",
    "df['primary_position'] = df['primary_position'].apply(fix_pos)\n",
    "df['label'] = df['label'].apply(lambda x: 'MLB' if x else 'MiLB')\n",
    "df['pos'] = df['primary_position'].apply(lambda x: 'SP' if x.endswith('HP') else 'BAT')\n",
    "df['parse'] = df['report'].apply(st.whitespace_nlp_with_sentences)\n",
    "df['parse_processed'] = df['text'].apply(st.whitespace_nlp_with_sentences)\n",
    "\n",
    "print(df.shape)\n",
    "df.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "corpus = st.CorpusFromPandas(text_df, \n",
    "                             category_col='label', \n",
    "                             text_col='report',\n",
    "                             nlp=nlp).build()\n",
    "\"\"\"\n",
    "\n",
    "corpus = st.CorpusFromParsedDocuments(df, category_col='label', parsed_col='parse').build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_explorer_html(corpus, category, not_category_name, filename, category_name=None, max_terms=100):\n",
    "    category_name = category_name or category\n",
    "    html = st.produce_scattertext_html(corpus,\n",
    "                                       category=category,\n",
    "                                       category_name=category_name,\n",
    "                                       not_category_name=not_category_name,\n",
    "                                       width_in_pixels=1000,\n",
    "                                       protocol='https',\n",
    "                                       pmi_threshold_coefficient=8,\n",
    "                                       minimum_term_frequency=20,\n",
    "                                       filter_unigrams=True,\n",
    "                                       max_terms=max_terms\n",
    "                                      )\n",
    "\n",
    "    open(filename, 'wb').write(html.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Viz\n",
    "\n",
    "#### Unprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_explorer_html(corpus, 'MLB', 'MiLB', 'assets/label-viz.html', max_terms=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MiLB freq</th>\n",
       "      <th>MLB freq</th>\n",
       "      <th>MLB Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alford</th>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nix</th>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0.999147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cecchini</th>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0.997598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robles</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0.996513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>banda</th>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0.996077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fried</th>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0.994667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arroyo</th>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0.994142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ciuffo</th>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0.994142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tellez</th>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0.993580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grisham</th>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0.993580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          MiLB freq  MLB freq  MLB Score\n",
       "term                                    \n",
       "alford            0        47   1.000000\n",
       "nix               0        43   0.999147\n",
       "cecchini          0        38   0.997598\n",
       "robles            0        35   0.996513\n",
       "banda             0        34   0.996077\n",
       "fried             0        31   0.994667\n",
       "arroyo            0        30   0.994142\n",
       "ciuffo            0        30   0.994142\n",
       "tellez            0        29   0.993580\n",
       "grisham           0        29   0.993580"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_freq_df = corpus.get_term_freq_df()\n",
    "term_freq_df['MLB Score'] = corpus.get_scaled_f_scores('MLB', scaler_algo='percentile')\n",
    "\n",
    "term_freq_df.to_csv('assets/label_term_freqs.csv')\n",
    "term_freq_df.nlargest(10, 'MLB Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = st.CorpusFromParsedDocuments(df, category_col='label', parsed_col='parse_processed') \\\n",
    "                                    .build() \\\n",
    "                                    .remove_terms([\n",
    "    'reid', \n",
    "    'foley', \n",
    "    'reid foley', \n",
    "    'pleskoff', \n",
    "    'debut', \n",
    "    'major', \n",
    "    'league',\n",
    "    'major league',\n",
    "    'his major',\n",
    "    'his big',\n",
    "    'organization debut',\n",
    "    'major organization',\n",
    "    'made his',\n",
    "    'league debut',\n",
    "    'the 2012',\n",
    "    'organization 2011'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MiLB freq</th>\n",
       "      <th>MLB freq</th>\n",
       "      <th>MLB Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trade</th>\n",
       "      <td>210</td>\n",
       "      <td>218</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the package</th>\n",
       "      <td>20</td>\n",
       "      <td>42</td>\n",
       "      <td>0.999735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>at age</th>\n",
       "      <td>144</td>\n",
       "      <td>167</td>\n",
       "      <td>0.999512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>as part</th>\n",
       "      <td>87</td>\n",
       "      <td>105</td>\n",
       "      <td>0.997560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traded</th>\n",
       "      <td>116</td>\n",
       "      <td>118</td>\n",
       "      <td>0.997343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>youngest</th>\n",
       "      <td>54</td>\n",
       "      <td>78</td>\n",
       "      <td>0.997062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>three team</th>\n",
       "      <td>17</td>\n",
       "      <td>35</td>\n",
       "      <td>0.997009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>that sent</th>\n",
       "      <td>39</td>\n",
       "      <td>61</td>\n",
       "      <td>0.996948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>organization deal</th>\n",
       "      <td>34</td>\n",
       "      <td>56</td>\n",
       "      <td>0.996236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age 20</th>\n",
       "      <td>30</td>\n",
       "      <td>53</td>\n",
       "      <td>0.996151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   MiLB freq  MLB freq  MLB Score\n",
       "term                                             \n",
       "trade                    210       218   1.000000\n",
       "the package               20        42   0.999735\n",
       "at age                   144       167   0.999512\n",
       "as part                   87       105   0.997560\n",
       "traded                   116       118   0.997343\n",
       "youngest                  54        78   0.997062\n",
       "three team                17        35   0.997009\n",
       "that sent                 39        61   0.996948\n",
       "organization deal         34        56   0.996236\n",
       "age 20                    30        53   0.996151"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_freq_df = corpus.get_term_freq_df()\n",
    "term_freq_df['MLB Score'] = corpus.get_scaled_f_scores('MLB', scaler_algo='percentile')\n",
    "\n",
    "term_freq_df.to_csv('assets/processed_label_term_freqs.csv')\n",
    "term_freq_df.nlargest(10, 'MLB Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_explorer_html(corpus, 'MLB', 'MiLB', 'assets/processed-label-viz.html', max_terms=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "unigram_corpus = (corpus.get_stoplisted_unigram_corpus())\n",
    "\n",
    "topic_model = st.SentencesForTopicModeling(\n",
    "    unigram_corpus).get_topics_from_model(Pipeline([\n",
    "        ('tfidf', TfidfTransformer(sublinear_tf=True)),\n",
    "        ('nmf', (NMF(n_components=50, alpha=.1, l1_ratio=.5, random_state=0)))\n",
    "    ]),\n",
    "                                          num_terms_per_topic=10)\n",
    "\n",
    "topic_feature_builder = st.FeatsFromTopicModel(topic_model)\n",
    "\n",
    "topic_corpus = st.CorpusFromParsedDocuments(\n",
    "    df,\n",
    "    category_col='label',\n",
    "    parsed_col='parse_processed',\n",
    "    feats_from_spacy_doc=topic_feature_builder).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11726793"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = st.produce_scattertext_explorer(\n",
    "    topic_corpus,\n",
    "    category='MLB',\n",
    "    category_name='MLB',\n",
    "    not_category_name='MiLB',\n",
    "    width_in_pixels=1000,\n",
    "    metadata=df['label'],\n",
    "    use_non_text_features=True,\n",
    "    use_full_doc=True,\n",
    "    pmi_threshold_coefficient=0,\n",
    "    topic_model_term_lists=topic_feature_builder.get_top_model_term_lists(),\n",
    "    topic_model_preview_size=20)\n",
    "\n",
    "open('assets/topic_model.html', 'wb').write(html.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Position Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_corpus = corpus.recategorize(df['pos'])\n",
    "corpus_explorer_html(pos_corpus, 'BAT', 'Pitcher', 'assets/pos-viz.html', category_name='Hitter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "emb_label_corpus = corpus.get_stoplisted_unigram_corpus()\n",
    "emb_pos_corpus = pos_corpus.get_stoplisted_unigram_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7926310"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = st.produce_projection_explorer(emb_label_corpus,\n",
    "                                      word2vec_model=Word2Vec(size=100,\n",
    "                                                              window=5,\n",
    "                                                              min_count=20,\n",
    "                                                              workers=4),\n",
    "                                      projection_model=TSNE(),\n",
    "                                      category='MLB',\n",
    "                                      category_name='MLB',\n",
    "                                      not_category_name='MiLB',\n",
    "                                      metadata=df['label'],\n",
    "                                      width_in_pixels=1000,\n",
    "                                      protocol='https',\n",
    "                                      pmi_threshold_coefficient=8,\n",
    "                                      filter_unigrams=True,\n",
    "                                      max_terms=100\n",
    "                                     )\n",
    "\n",
    "open('assets/embedding-label-viz.html', 'wb').write(html.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7916561"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = st.produce_projection_explorer(emb_pos_corpus,\n",
    "                                      word2vec_model=Word2Vec(size=100,\n",
    "                                                              window=5,\n",
    "                                                              min_count=20,\n",
    "                                                              workers=4),\n",
    "                                      projection_model=TSNE(),\n",
    "                                      category='BAT',\n",
    "                                      category_name='Hitter',\n",
    "                                      not_category_name='Pitcher',\n",
    "                                      metadata=df['pos'],\n",
    "                                      width_in_pixels=1000,\n",
    "                                      protocol='https',\n",
    "                                      pmi_threshold_coefficient=8,\n",
    "                                      filter_unigrams=True,\n",
    "                                      max_terms=100\n",
    "                                     )\n",
    "\n",
    "open('assets/embedding-pos-viz.html', 'wb').write(html.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.nn import util\n",
    "from allennlp.data.fields import TextField, ListField\n",
    "from allennlp.data.instance import Instance\n",
    "from allennlp.data.tokenizers import Tokenizer, WordTokenizer, Token\n",
    "from allennlp.data.tokenizers.sentence_splitter import SpacySentenceSplitter\n",
    "from allennlp.data.token_indexers import TokenIndexer, SingleIdTokenIndexer\n",
    "from allennlp.data.vocabulary import Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"  A native of the Dominican Republic, Severino made an impressive full-season debut in 2013 at Class A Hagerstown. He continued that success the next season with Class A Advanced Potomac and in the Arizona Fall League. Severino's arm strength and athleticism behind the plate leave no doubt he has the skills necessary to catch in the big leagues. He blocks balls in the dirt well, already shows an aptitude for pitch framing and is improving as a game-caller.Severino made progress offensively in 2014, but his bat remains well behind his glove. He has some pop and his easy swing gives him a chance to eventually hit for more average. As he moves up to the upper levels of the Minor Leagues, his advanced defensive ability will allow the Nationals to be patient and allow his offense further develop.\""
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = df.sample(1).report.values[0]\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = WordTokenizer()\n",
    "splitter = SpacySentenceSplitter()\n",
    "token_indexers = {\"tokens\": SingleIdTokenIndexer()}\n",
    "vocab = Vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<allennlp.data.fields.list_field.ListField at 0x1b6a8ada0>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = splitter.split_sentences(report)\n",
    "tokenized_sents = [[Token(w) for w in tokenizer.tokenize(sent)] for sent in sentences]\n",
    "\n",
    "sent_fields = ListField([TextField(s, token_indexers) for s in tokenized_sents])\n",
    "sent_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inst = Instance({'tokens': sent_fields})\n",
    "#vocab.index(inst)\n",
    "\n",
    "inst.fields['tokens'].index(vocab)\n",
    "tokens = inst.as_tensor_dict()['tokens']\n",
    "\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected a tensor with dimension 2 or 3, found 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-172a54724380>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text_field_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_wrapping_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#== tokens['tokens']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/allennlp/nn/util.py\u001b[0m in \u001b[0;36mget_text_field_mask\u001b[0;34m(text_field_tensors, num_wrapping_dims)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcharacter_tensor\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expected a tensor with dimension 2 or 3, found {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmallest_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected a tensor with dimension 2 or 3, found 1"
     ]
    }
   ],
   "source": [
    "util.get_text_field_mask(tokens, num_wrapping_dims=1) #== tokens['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)[['text', 'label']].to_json('ai2test.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 11.86it/s]\n"
     ]
    }
   ],
   "source": [
    "from allennlp.data.dataset_readers.dataset_reader import DatasetReader\n",
    "\n",
    "jsr = DatasetReader.by_name(\"text_classification_json\")(segment_sentences=True)\n",
    "train = jsr.read('ai2test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tf = vars(train[0].fields['tokens'])['field_list'][0]\n",
    "#tf.as_tensor()\n",
    "inst = train[1].fields['tokens']\n",
    "inst.index(vocab)\n",
    "sents = inst.as_tensor(inst.get_padding_lengths())\n",
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = {'tokens': torch.stack([sents['tokens'], sents['tokens']], dim=0)}\n",
    "util.get_text_field_mask(x)#, num_wrapping_dims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(util.get_text_field_mask(x).sum(dim=1) > 1).byte()\n",
    "util.get_text_field_mask({'_': util.get_text_field_mask(x)}).eq(util.get_text_field_mask(x)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 8, 25]), torch.Size([2, 8]))"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = torch.randn(2, 8, 25)\n",
    "w = torch.randn(2, 8)\n",
    "\n",
    "\n",
    "docs.size(), w.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (53) must match the size of tensor b (25) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-265-c82aef566f30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m53\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m53\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (53) must match the size of tensor b (25) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "torch.randn(2, 1, 8, 53) * torch.randn(2, 8, 53, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 8.8707e-01, -1.2449e-02,  2.3112e-01,  1.2071e-02,  2.8455e-01,\n",
       "          -4.6274e-02,  5.4149e-01,  7.8635e-03, -2.6913e-01, -3.7698e-01,\n",
       "           1.2731e+00,  4.1280e-01, -1.0382e+00, -1.3867e+00, -1.7997e+00,\n",
       "          -1.2317e+00, -7.0544e-01, -2.2487e-01, -8.3829e-01,  4.5262e-01,\n",
       "          -3.7627e-01, -1.1786e-01, -8.9341e-02, -4.8377e-01,  6.2320e-01],\n",
       "         [ 5.4593e-01,  1.5988e-02,  1.3876e-01,  3.7775e-01, -6.5739e-02,\n",
       "           3.0363e-01,  8.8584e-01, -3.0559e-01, -4.9869e-01,  9.3277e-01,\n",
       "           6.1826e-01, -5.6569e-01,  2.5759e-01,  3.2612e-02,  6.7454e-01,\n",
       "          -8.7706e-01,  1.2436e+00,  7.8087e-01,  4.2654e-02, -5.7773e-01,\n",
       "          -3.8928e-01,  5.4844e-01, -1.2237e-01,  5.5231e-01, -6.3929e-01],\n",
       "         [-9.5257e-01, -1.4470e+00, -5.2574e-01, -7.3909e-01,  5.3668e-01,\n",
       "          -7.4040e-01, -1.0426e+00,  1.0805e-01, -1.4923e-01, -8.9584e-01,\n",
       "          -6.7993e-01, -2.1030e-01, -2.6861e-04, -1.1963e-01,  9.8023e-02,\n",
       "           5.3018e-01, -1.6432e-01, -8.6401e-02,  9.2967e-01,  3.5980e-01,\n",
       "          -1.0441e+00, -6.3745e-01,  6.9492e-01, -5.1251e-02,  4.1835e-02],\n",
       "         [-1.4176e+00,  1.3515e+00,  1.9610e+00,  8.9443e-02,  8.0292e-01,\n",
       "           1.8704e+00, -1.6205e+00, -2.4075e-01,  1.9711e-01,  1.6299e-01,\n",
       "          -2.1952e-02,  1.0360e+00, -3.2483e-02, -1.9073e+00, -4.5677e-01,\n",
       "           1.6924e+00, -1.7808e+00,  4.9055e-01, -6.7486e-01, -6.3285e-01,\n",
       "           1.1276e+00, -1.1267e+00,  1.4731e+00, -8.9259e-01, -5.3900e-02],\n",
       "         [-6.0673e-01, -2.6171e-01, -1.3472e-01, -4.4854e-01, -2.6013e-01,\n",
       "          -5.6611e-01,  8.9846e-01,  4.8669e-01, -1.0547e-02,  7.7410e-02,\n",
       "           3.7280e-01, -3.0485e-01, -1.5833e-01, -2.5439e-01, -3.4465e-01,\n",
       "          -8.3228e-02, -6.2746e-01,  5.3335e-01, -2.3932e-01, -3.8474e-01,\n",
       "          -5.4836e-01, -3.6008e-01,  1.3773e-01, -2.7470e-01, -2.2116e-01],\n",
       "         [-1.5237e+00,  1.5535e+00, -2.4813e+00,  5.9798e+00,  1.3451e-01,\n",
       "          -5.8802e-02,  5.7169e-01,  1.1011e+00, -8.7549e-01,  3.6432e+00,\n",
       "           2.5321e+00,  1.8874e+00, -2.5448e-01, -1.9189e+00, -2.3999e-01,\n",
       "          -9.8347e-01,  9.0410e-01, -3.0482e-01,  5.9157e-01, -1.7719e-01,\n",
       "           2.9170e+00, -2.4921e+00, -2.4040e+00,  5.0212e-01,  4.3213e-01],\n",
       "         [-1.6092e-01, -1.4176e+00,  2.8843e-01, -4.0368e-01,  2.1679e+00,\n",
       "           3.9225e+00, -3.5020e+00, -1.0466e+00,  4.5580e-01,  9.6485e-01,\n",
       "          -1.6180e+00, -7.0936e-01,  1.8074e+00, -7.0809e-01,  3.3103e-01,\n",
       "          -2.9939e+00,  1.7621e+00,  7.0776e-01,  2.7084e+00, -1.6287e+00,\n",
       "          -1.8655e-01, -9.2535e-01,  2.1057e+00, -2.3287e+00, -7.3022e-01],\n",
       "         [ 1.3553e-01, -1.0883e-01, -2.7518e-01, -4.3840e-01, -2.0072e-01,\n",
       "          -6.2310e-01, -7.8214e-01, -1.0382e-01, -1.4945e+00, -1.5165e-01,\n",
       "           5.2281e-01, -7.0003e-02,  1.0969e+00,  1.7582e-01,  4.1018e-01,\n",
       "           8.1204e-01,  9.6076e-01,  1.0215e+00,  5.1431e-01, -1.0151e+00,\n",
       "           1.7207e-02, -1.6495e-02,  1.0403e+00,  8.3052e-02, -1.3356e-01]],\n",
       "\n",
       "        [[ 6.2553e-01, -1.9141e-01, -6.9467e-01,  1.0487e-01, -1.7808e+00,\n",
       "          -1.6683e+00,  3.7677e-01, -3.6019e-01, -8.6957e-01, -3.8624e-01,\n",
       "          -9.6064e-02, -1.3131e+00, -8.4506e-01, -2.1587e-01,  5.6317e-01,\n",
       "           4.9973e-01, -7.3659e-01, -4.1532e-01,  8.1747e-02, -1.0843e-01,\n",
       "          -5.5448e-01, -1.0207e-01,  1.6106e+00,  3.3301e-01,  1.3834e+00],\n",
       "         [-5.6807e-01,  4.1462e-01, -9.3687e-01,  8.5219e-01, -4.7289e-01,\n",
       "          -4.1118e-01,  5.2937e-01, -4.2698e-01,  7.5600e-01, -2.2630e-01,\n",
       "          -9.2577e-01, -4.2599e-01, -3.2975e-01,  1.4936e+00,  3.4921e-02,\n",
       "           6.0911e-01,  4.2548e-01, -3.5996e-01, -4.0247e-01,  6.1747e-01,\n",
       "          -5.5421e-01,  1.0976e-01, -1.6217e-02, -6.7923e-01, -9.0566e-02],\n",
       "         [-6.9532e-01, -2.6492e-02, -4.1426e-01,  3.6597e-03,  1.4513e+00,\n",
       "          -6.5690e-01, -1.1379e+00,  4.1174e-01, -1.3248e+00,  7.4852e-01,\n",
       "           5.9060e-01,  1.3596e+00, -3.8720e-01,  1.3300e+00,  2.4035e-01,\n",
       "          -1.3758e-01,  8.0246e-01, -1.0449e+00, -1.0041e+00, -9.6919e-02,\n",
       "           9.2247e-01, -6.6340e-01, -6.6046e-02, -2.5123e-01, -5.3209e-01],\n",
       "         [ 1.5574e+00, -1.0437e+00,  7.4815e-01, -8.6167e-01,  3.2453e-02,\n",
       "           1.6229e-01, -1.0319e+00, -2.5805e-01,  1.3387e+00,  8.8658e-01,\n",
       "           4.7812e-01,  2.9179e-01,  1.5328e+00, -2.2582e+00, -1.9032e-01,\n",
       "          -1.5957e+00, -1.4620e+00,  1.1740e+00, -7.5419e-01,  1.3463e+00,\n",
       "           1.0880e+00, -1.5092e+00, -1.9182e-01, -3.5798e-01,  1.4528e+00],\n",
       "         [ 3.4790e-01,  5.0715e-01,  8.8301e-01, -3.8842e-01, -1.0835e+00,\n",
       "           2.5813e+00, -7.2461e-01, -1.4166e+00,  1.1483e+00,  7.5329e-02,\n",
       "           1.6142e+00, -9.1627e-02,  1.2975e-02, -2.6380e-02,  1.7881e+00,\n",
       "           9.9968e-01,  6.0455e-01,  4.8510e-01, -1.1932e+00, -1.4077e-01,\n",
       "          -1.0697e+00, -6.3183e-01,  1.6163e+00,  1.3907e-01,  1.8479e+00],\n",
       "         [ 7.6048e-02, -1.7600e-02, -3.5355e-03, -7.2089e-03,  1.1430e-02,\n",
       "          -2.3416e-01,  7.9347e-02, -8.1421e-02, -1.4564e-01, -2.1726e-01,\n",
       "           2.6233e-02, -1.1147e-01, -1.0101e-01, -6.2403e-03, -5.0938e-02,\n",
       "           2.4477e-01, -1.3199e-01,  1.0551e-01, -4.6113e-02,  3.2305e-02,\n",
       "          -1.8457e-02,  1.7290e-02, -2.1076e-01, -1.2131e-01, -2.8059e-01],\n",
       "         [-7.3423e-02, -1.4796e-01,  1.9338e-01, -1.4358e-01,  3.1186e-01,\n",
       "           2.9487e-01, -6.6815e-03, -8.2966e-02,  1.3982e-01,  4.8194e-01,\n",
       "          -1.5825e-01, -3.0236e-01, -3.1223e-01, -2.2260e-02, -5.2091e-01,\n",
       "           9.9029e-03, -9.4875e-02, -6.3641e-03,  2.3616e-01,  6.6882e-02,\n",
       "           1.6385e-01,  1.8917e-01,  3.1015e-01, -5.6687e-02, -2.8243e-01],\n",
       "         [-1.0442e+00,  3.8172e-01, -5.3046e-01, -3.6664e-02, -7.7308e-01,\n",
       "           7.1559e-01,  3.6415e-01, -4.5297e-01,  8.7727e-01,  1.6645e-01,\n",
       "          -4.0782e-01,  5.1551e-01,  4.8966e-01, -1.4336e-01,  6.2853e-01,\n",
       "           2.5470e-01,  4.4432e-01,  3.2413e-02,  1.0598e+00, -4.7568e-01,\n",
       "          -6.8670e-01, -2.2231e-02, -7.3460e-01, -4.5963e-01,  4.1374e-01]]])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.matmul(docs, w.T).size()\n",
    "# docs * w.unsqueeze(-1)\n",
    "\n",
    "matrix = torch.randn(1, 9, 25)\n",
    "\n",
    "matrix.bmm(vector.unsqueeze(-1)).squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 8, 25]), torch.Size([8, 2, 2]))"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d, w = torch.nn.MultiheadAttention(25, 1)(docs, docs, docs)\n",
    "d.size(), w.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'field_list': [<allennlp.data.fields.text_field.TextField at 0x1bfc77a58>,\n",
       "  <allennlp.data.fields.text_field.TextField at 0x1bfc77d68>,\n",
       "  <allennlp.data.fields.text_field.TextField at 0x1bfc9d4a8>,\n",
       "  <allennlp.data.fields.text_field.TextField at 0x1bfc9d898>,\n",
       "  <allennlp.data.fields.text_field.TextField at 0x1bfc9dc88>,\n",
       "  <allennlp.data.fields.text_field.TextField at 0x1bb328320>,\n",
       "  <allennlp.data.fields.text_field.TextField at 0x1bb328748>,\n",
       "  <allennlp.data.fields.text_field.TextField at 0x1bb328dd8>]}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inst = jsr.text_to_instance(text=report)\n",
    "#inst.fields['tokens'].index(vocab)\n",
    "#inst.fields['tokens'].as_tensor(inst.get_padding_lengths())\n",
    "vars(inst.fields['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TextField' object has no attribute 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-145-3189467b4a9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text_field_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m's1'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokens'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'field_list'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/allennlp/nn/util.py\u001b[0m in \u001b[0;36mget_text_field_mask\u001b[0;34m(text_field_tensors, num_wrapping_dims)\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtext_field_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mtensor_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext_field_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m     \u001b[0mtensor_dims\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/allennlp/nn/util.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtext_field_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mtensor_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext_field_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m     \u001b[0mtensor_dims\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TextField' object has no attribute 'dim'"
     ]
    }
   ],
   "source": [
    "util.get_text_field_mask({'s1': vars(inst.fields['tokens'])['field_list'][0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "notify_time": "10"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
