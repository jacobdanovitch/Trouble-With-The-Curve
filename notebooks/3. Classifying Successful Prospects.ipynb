{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TWTC TorchHub",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/gist/jacobdanovitch/285b42364083f9db89db4881b97068ff/twtc-torchhub.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Crnv3WsXXz5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install regex requests sentencepiece sacremoses"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYMKWCMAXGWQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import multiprocessing as mp\n",
        "from tqdm.auto import tqdm; tqdm.pandas()\n",
        "\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from sklearn.metrics import classification_report, balanced_accuracy_score, f1_score, accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGg95kxiaejw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tqdm_parallel(fn, vals, processes):\n",
        "    with mp.Pool(processes=processes) as pool, tqdm(total=len(vals)) as pbar:\n",
        "        for x in pool.imap(fn, vals):\n",
        "            pbar.update()\n",
        "            yield x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wsho4NcQkCM5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_torchhub_transformer(model):\n",
        "  tokenizer = torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', model)    \n",
        "  transformer = torch.hub.load('huggingface/pytorch-transformers', 'model', model).eval().cuda()\n",
        "\n",
        "  return transformer, tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAE4-5v7iSwc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "6bbbfdde-f2ef-4e09-b0f2-1c1626fc8bb0"
      },
      "source": [
        "#xlnet, tokenizer = load_torchhub_transformer('xlnet-base-cased')\n",
        "#distilbert, tokenizer = load_torchhub_transformer('distilbert-base-uncased')\n",
        "#gpt2, tokenizer = load_torchhub_transformer('gpt2-medium')\n",
        "\n",
        "roberta = torch.hub.load('pytorch/fairseq', 'roberta.large').eval().cuda()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_fairseq_master\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loading archive file http://dl.fbaipublicfiles.com/fairseq/models/roberta.large.tar.gz from cache at /root/.cache/torch/pytorch_fairseq/83e3a689e28e5e4696ecb0bbb05a77355444a5c8a3437e0f736d8a564e80035e.c687083d14776c1979f3f71654febb42f2bb3d9a94ff7ebdfe1ac6748dba89d2\n",
            "| dictionary: 50264 types\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBhSgQzujI_m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transformer_featurizer(model, tokenizer, txt):\n",
        "  tok = tokenizer.encode(txt)[:512]\n",
        "  tok = torch.tensor([tok])\n",
        "  features = model(tok.to('cuda:0'))[0].squeeze(0).cpu().detach().numpy()\n",
        "  features = features.mean(axis=0)\n",
        "  \n",
        "  return features\n",
        "\n",
        "\n",
        "def extract_transformer_features(model, tokenizer, report):\n",
        "  encoder = lambda x: transformer_featurizer(model, tokenizer, x)\n",
        "  embedded = report.progress_apply(encoder).values\n",
        "  return np.matrix(embedded.tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGnZog3oXWF4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def roberta_encoder(x):\n",
        "  return roberta.encode(x)[:512]\n",
        "\n",
        "def roberta_featurizer(tokens):\n",
        "    features = roberta.extract_features(tokens).squeeze(0).cpu().detach().numpy()\n",
        "    features = features.mean(axis=0)\n",
        "    \n",
        "    return features\n",
        "\n",
        "def extract_roberta_features(report):\n",
        "  tokens = tqdm_parallel(roberta_encoder, report, processes=8)\n",
        "  embedded = np.matrix([roberta_featurizer(r) for r in tokens])\n",
        "\n",
        "  return embedded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRSRqsD7YDkI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "20a5a832-7f11-4467-da74-e5612e335785"
      },
      "source": [
        "df = pd.read_csv('preprocessed.csv')[['report', 'label']].copy()\n",
        "\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5824, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>report</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PERSON is a Level NUMBER sex offender and woul...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PERSON made headlines for all the wrong reason...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The ORGANIZATION have acquired PERSON twice, f...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Signed for an above-slot $NUMBER million as a ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>It often takes time for those high-ceilinged, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              report  label\n",
              "0  PERSON is a Level NUMBER sex offender and woul...      0\n",
              "1  PERSON made headlines for all the wrong reason...      0\n",
              "2  The ORGANIZATION have acquired PERSON twice, f...      1\n",
              "3  Signed for an above-slot $NUMBER million as a ...      1\n",
              "4  It often takes time for those high-ceilinged, ...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjPZUezgXjU7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "183c66fd-57ec-4617-b81d-35fe593565b4"
      },
      "source": [
        "#X = extract_transformer_features(gpt2, tokenizer, df.report)\n",
        "#X = TfidfVectorizer().fit_transform(df.report)\n",
        "X = extract_roberta_features(df.report)\n",
        "\n",
        "y = df['label']\n",
        "\n",
        "X.shape, y.shape"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5824, 9804), (5824,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pjZx1iWdz4S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "079215f8-e2f2-437d-c689-c5beaab7eeae"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "X_train.shape"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4659, 9804)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XK9nJ_RXZfrg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "1d2101dc-e6fb-4bd2-ee8c-f124d56c7364"
      },
      "source": [
        "clf = LinearSVC(max_iter=2000)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "preds = clf.predict(X_test)\n",
        "test_data = (y_test, preds)\n",
        "\n",
        "print(classification_report(y_test, preds))\n",
        "\n",
        "print(accuracy_score(*test_data))\n",
        "print(f1_score(*test_data))\n",
        "print(balanced_accuracy_score(*test_data))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.95      0.90       921\n",
            "           1       0.64      0.36      0.47       244\n",
            "\n",
            "    accuracy                           0.82      1165\n",
            "   macro avg       0.75      0.66      0.68      1165\n",
            "weighted avg       0.81      0.82      0.81      1165\n",
            "\n",
            "0.8248927038626609\n",
            "0.46596858638743455\n",
            "0.6557755290934657\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}